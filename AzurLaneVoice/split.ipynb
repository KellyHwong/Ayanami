{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Date    : Apr-12-23 11:41\n",
    "# @Author  : Kelly Hwong (dianhuangkan@gmail.com)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_name = \"Ayanami\"\n",
    "character_path = f\"../characters/{character_name}-Voice-Text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(character_path, \"metadata_aligh.csv\"), delimiter='|', na_filter= False)\n",
    "df = df[df[\"dialogue_jp\"] != \"None\"]\n",
    "num_samples = len(df)\n",
    "\n",
    "audiopaths_and_text = os.path.join(character_path, \"metadata.csv\")\n",
    "df.to_csv(audiopaths_and_text, columns=[\"filename\",\n",
    "          \"dialogue_jp\"], sep='|', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filepaths_and_text(filename, split=\"|\"):\n",
    "  with open(filename, encoding='utf-8') as f:\n",
    "    filepaths_and_text = [line.strip().split(split) for line in f]\n",
    "  return filepaths_and_text\n",
    "\n",
    "\n",
    "audiopaths_and_text = os.path.join(character_path, \"metadata.csv\")\n",
    "audiopaths_and_text = load_filepaths_and_text(audiopaths_and_text)\n",
    "\n",
    "random.seed(1234)\n",
    "random.shuffle(audiopaths_and_text)\n",
    "num_samples = len(audiopaths_and_text)\n",
    "\n",
    "val_split = 0.2\n",
    "np.random.seed(42)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    list(range(num_samples)), test_size=val_split, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = [], []\n",
    "for idx in range(num_samples):\n",
    "    if idx in train_idx:\n",
    "        train_set.append(audiopaths_and_text[idx])\n",
    "    elif idx in val_idx:\n",
    "        val_set.append(audiopaths_and_text[idx])\n",
    "print(len(train_set))\n",
    "print(len(val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = os.path.join(\"AzurLaneVoice\", character_name, \"mp3\")\n",
    "\n",
    "splits = [\"train\", \"val\"]\n",
    "datasets = [train_set, val_set]\n",
    "for split, dataset in zip(splits, datasets):\n",
    "    filename = character_name.lower()+\"_audio_text_\"+split+\"_filelist.txt\"\n",
    "    filepath = os.path.join(character_name, \"filelists\", filename)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        lines = ['|'.join([os.path.join(prefix, _[0]), _[1]])+'\\n' for _ in dataset]\n",
    "        f.writelines(lines)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
